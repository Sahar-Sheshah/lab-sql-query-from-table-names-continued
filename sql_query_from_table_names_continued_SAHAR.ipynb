{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
      "metadata": {
        "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
      },
      "source": [
        "# SQL query from table names - Continued"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G7KtH2_tinZ",
        "outputId": "491c10ea-2f20-4c2d-a279-2c70dd5fbd07"
      },
      "id": "3G7KtH2_tinZ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a03f026a",
      "metadata": {
        "id": "a03f026a"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
      "metadata": {
        "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
      },
      "source": [
        "## The old Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "922f8d24",
      "metadata": {
        "id": "922f8d24"
      },
      "outputs": [],
      "source": [
        "#The old prompt\n",
        "old_context = [ {'role':'system', 'content':\"\"\"\n",
        "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
        "this is your SQL, and after that an SQL that can do what the user request. \\\n",
        "Your Database is composed by a SQL database with some tables. \\\n",
        "Try to maintain the SQL order simple.\n",
        "Put the SQL command in white letters with a black background, and just after \\\n",
        "a simple and concise text explaining how it works.\n",
        "If the user ask for something that can not be solved with an SQL Order \\\n",
        "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
        "can be solved with SQL.\n",
        "\"\"\"} ]\n",
        "\n",
        "old_context.append( {'role':'system', 'content':\"\"\"\n",
        "first table:\n",
        "{\n",
        "  \"tableName\": \"employees\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"nombre\": \"ID_usr\",\n",
        "      \"tipo\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"nombre\": \"name\",\n",
        "      \"tipo\": \"varchar\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "})\n",
        "\n",
        "old_context.append( {'role':'system', 'content':\"\"\"\n",
        "second table:\n",
        "{\n",
        "  \"tableName\": \"salary\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"nombre\": \"ID_usr\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"year\",\n",
        "      \"type\": \"date\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"salary\",\n",
        "      \"type\": \"float\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "})\n",
        "\n",
        "old_context.append( {'role':'system', 'content':\"\"\"\n",
        "third table:\n",
        "{\n",
        "  \"tablename\": \"studies\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"name\": \"ID\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ID_usr\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"educational_level\",\n",
        "      \"type\": \"int\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Institution\",\n",
        "      \"type\": \"varchar\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"Years\",\n",
        "      \"type\": \"date\"\n",
        "    }\n",
        "    {\n",
        "      \"name\": \"Speciality\",\n",
        "      \"type\": \"varchar\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
      "metadata": {
        "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
      },
      "source": [
        "## New Prompt.\n",
        "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
        "\n",
        "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
        "\n",
        "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5334f942",
      "metadata": {
        "id": "5334f942"
      },
      "outputs": [],
      "source": [
        "context = [ {'role':'system', 'content':\"\"\"\n",
        " CREATE SEVERAL (3+) TABLES HERE\n",
        "\"\"\"} ]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
      "metadata": {
        "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
      },
      "outputs": [],
      "source": [
        "#FEW SHOT SAMPLES\n",
        "context.append( {'role':'system', 'content':\"\"\"\n",
        " -- Maintain the SQL order simple and efficient as you can, using valid SQL Lite, answer the following questions for the table provided above.\n",
        "WRITE IN YOUR CONTEXT QUERIES HERE\n",
        "\"\"\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b90f417a",
      "metadata": {
        "id": "b90f417a"
      },
      "outputs": [],
      "source": [
        "#Functio to call the model.\n",
        "def return_CCRMSQL(user_message, context):\n",
        "    client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=OPENAI_API_KEY,\n",
        ")\n",
        "\n",
        "    newcontext = context.copy()\n",
        "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=newcontext,\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "    return (response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
      "metadata": {
        "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
      },
      "source": [
        "## NL2SQL Samples\n",
        "We're going to review some examples generated with the old prompt and others with the new prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "59e8202c-ce34-487e-9037-c65a263423ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59e8202c-ce34-487e-9037-c65a263423ed",
        "outputId": "0c391536-d0e1-40e9-97ca-45a8346f99a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I see you have not provided any tables for me to work with. Could you please provide the tables so that I can assist you with your queries?\n"
          ]
        }
      ],
      "source": [
        "#new\n",
        "context_user = context.copy()\n",
        "print(return_CCRMSQL(\"\"\"YOUR QUERY HERE\"\"\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
        "outputId": "fdc472d7-c9c6-4276-d7eb-97f3efaa1847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "```sql\n",
            "\n",
            "SELECT * \n",
            "FROM employees;\n",
            "```\n",
            "This SQL query selects all data from the \"employees\" table.\n"
          ]
        }
      ],
      "source": [
        "#old\n",
        "old_context_user = old_context.copy()\n",
        "print(return_CCRMSQL(\"YOUR QUERY HERE\", old_context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
        "outputId": "19a0524a-08d7-4631-b79b-ecb9ca94f767"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I see that you have not provided any tables for me to work with. Could you please provide the tables so that I can assist you with your queries?\n"
          ]
        }
      ],
      "source": [
        "#new\n",
        "print(return_CCRMSQL(\"YOUR QUERY HERE\", context_user))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
        "outputId": "56288263-b65e-4334-803a-69c5afb174ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is your SQL:\n",
            "```sql\n",
            "\n",
            "Please provide a specific query to assist you.\n"
          ]
        }
      ],
      "source": [
        "#old\n",
        "print(return_CCRMSQL(\"YOUR QUERY HERE\", old_context_user))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
      "metadata": {
        "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
      },
      "source": [
        "# Exercise\n",
        " - Complete the prompts similar to what we did in class.\n",
        "     - Try at least 3 versions\n",
        "     - Be creative\n",
        " - Write a one page report summarizing your findings.\n",
        "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
        "     - What did you learn?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv(find_dotenv())\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Function to query OpenAI with context and user question\n",
        "def return_CCRMSQL(user_message, context, model=\"gpt-3.5-turbo\", temperature=0):\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    new_context = context.copy()\n",
        "    new_context.append({'role': 'user', 'content': f\"question: {user_message}\"})\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=new_context,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Context: restaurant sales database with tables and sample data\n",
        "context = [{'role': 'system', 'content': \"\"\"\n",
        "CREATE TABLE customers (\n",
        "    customer_id INTEGER PRIMARY KEY,\n",
        "    name VARCHAR(100),\n",
        "    phone VARCHAR(20)\n",
        ");\n",
        "\n",
        "CREATE TABLE menu_items (\n",
        "    item_id INTEGER PRIMARY KEY,\n",
        "    name VARCHAR(100),\n",
        "    category VARCHAR(50),\n",
        "    price FLOAT\n",
        ");\n",
        "\n",
        "CREATE TABLE orders (\n",
        "    order_id INTEGER PRIMARY KEY,\n",
        "    customer_id INTEGER,\n",
        "    item_id INTEGER,\n",
        "    quantity INTEGER,\n",
        "    order_date DATE\n",
        ");\n",
        "\n",
        "-- Sample Data\n",
        "INSERT INTO customers VALUES (1, 'Sarah', '123-456'), (2, 'Ali', '789-101'), (3, 'Lina', '202-303');\n",
        "INSERT INTO menu_items VALUES (1, 'Burger', 'Main', 8.5), (2, 'Fries', 'Side', 3.0), (3, 'Cola', 'Drink', 2.0);\n",
        "INSERT INTO orders VALUES (1001, 1, 1, 2, '2024-03-01'), (1002, 1, 2, 1, '2024-03-01'), (1003, 2, 3, 3, '2024-03-02');\n",
        "\n",
        "-- Example Queries\n",
        "-- Q: What are the menu items?\n",
        "-- SQL: SELECT name FROM menu_items;\n",
        "\n",
        "-- Q: How many times was each item ordered?\n",
        "-- SQL: SELECT name, SUM(quantity) AS total_sold FROM menu_items m JOIN orders o ON m.item_id = o.item_id GROUP BY name;\n",
        "\n",
        "-- Q: What did customer Sarah order?\n",
        "-- SQL: SELECT m.name, o.quantity FROM orders o JOIN menu_items m ON o.item_id = m.item_id JOIN customers c ON o.customer_id = c.customer_id WHERE c.name = 'Sarah';\n",
        "\"\"\"}]\n",
        "\n",
        "# Test queries\n",
        "print(return_CCRMSQL(\"List all menu item names and their prices.\", context))\n",
        "print(return_CCRMSQL(\"How many times was each item ordered?\", context))\n",
        "print(return_CCRMSQL(\"Show orders placed by customer Sarah.\", context))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6LXA9Gyx79_",
        "outputId": "47195650-62ba-441f-aa9e-8fee50ba42c3"
      },
      "id": "W6LXA9Gyx79_",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```sql\n",
            "SELECT name, price\n",
            "FROM menu_items;\n",
            "```\n",
            "```sql\n",
            "SELECT name, SUM(quantity) AS total_sold \n",
            "FROM menu_items m \n",
            "JOIN orders o ON m.item_id = o.item_id \n",
            "GROUP BY name;\n",
            "```\n",
            "```sql\n",
            "SELECT m.name AS item_name, o.quantity, o.order_date\n",
            "FROM orders o\n",
            "JOIN menu_items m ON o.item_id = m.item_id\n",
            "JOIN customers c ON o.customer_id = c.customer_id\n",
            "WHERE c.name = 'Sarah';\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restaurant Sales.\n",
        "\n",
        "\n",
        "### Key Findings\n",
        "-Structured prompts that include CREATE TABLE, sample inserts, and example queries improved GPT's accuracy significantly.\n",
        "\n",
        "-Few-shot examples helped guide GPT in understanding expected syntax and reduced hallucinations.\n",
        "\n",
        "-Adding descriptive table names and meaningful field names (e.g., order_date, customer_id) made a difference in output clarity.\n",
        "\n",
        "### That Didn't Work Well\n",
        "-When context lacked clear relationships between tables (e.g., missing foreign key-like links), GPT made assumptions that were incorrect.\n",
        "\n",
        "-Ambiguous or overly short user questions led to vague or incorrect SQL queries.\n",
        "\n",
        "-In some tests, GPT hallucinated column names not present in the schema when few-shot examples were missing.\n",
        "\n",
        "### What I Learned\n",
        "-Prompt engineering matters a lot. The more structured and concrete the context, the better GPT performs.\n",
        "\n",
        "-Using SQL-style schema with actual data examples is much better than plain English descriptions.\n",
        "\n",
        "-Few-shot learning is powerful—even 2-3 good examples greatly increase output reliability.\n",
        "\n",
        "-GPT can be a solid tool for text-to-SQL translation, but guardrails are needed to catch edge cases or wrong assumptions."
      ],
      "metadata": {
        "id": "5I9PxX2NydU0"
      },
      "id": "5I9PxX2NydU0"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}